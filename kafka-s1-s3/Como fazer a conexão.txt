KAFKA para linkar S1 no S3

passo 1:

mkdir kafka-s1-s3 && cd kafka-s1-s3

passo 2: criar  docker-compose.yml e colocar esse codigo dentro

version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

passo 3:

docker-compose up -d

passo 4:

docker ps

passo 5: abrir topico iterativo do kafka

docker exec -it kafka-s1-s3-kafka-1 bash

passo 6:

kafka-topics --create \
  --topic s1-s3-comunicacao \
  --bootstrap-server localhost:9092 \
  --partitions 1 \
  --replication-factor 1

passo 7: criar python para fazer a msg

pip install kafka-python

passo 8: criar arquivo s1.py

from kafka import KafkaProducer
import json
import time

producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

while True:
    mensagem = {"sistema": "S1", "dados": "Mensagem de teste"}
    producer.send('s1-s3-comunicacao', mensagem)
    print("Mensagem enviada:", mensagem)
    time.sleep(5)

passo 9: criar arquivo s3.py

from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    's1-s3-comunicacao',
    bootstrap_servers='localhost:9092',
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    auto_offset_reset='earliest',
    group_id='grupo-s3'
)

print("Esperando mensagens do t√≥pico...")

for mensagem in consumer:
    print("Mensagem recebida no S3:", mensagem.value)

passo 10: rodar o sistema

python s3.py (terminal 1)
python s1.py (terminal 2)




